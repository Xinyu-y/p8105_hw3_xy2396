---
title: "Homework 3"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

```{r results='hide', message=FALSE}
library(tidyverse)
library(ggridges)
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("instacart")
```

The data 'instacart' contains `r nrow(instacart)` observations and `r ncol(instacart)` variables. 

There are four character vairables: 'eval_set'(which evaluation set this order belongs in), 'product_name'(name of product), 'aisle'(name of aisle), and 'department'(name of department);
All the other variables are integer, such as 'order_id'(order identifier), 'order_dow'(day of the week on which the order was placed), and 'order_hour_of_day'(the hour of the day on which the order was placed). 
Here listed few observations as example:
```{r echo=FALSE}
head(instacart, n = 3) %>% knitr::kable()
```

```{r}
aisle = 
  instacart %>% 
  select(aisle, aisle_id) %>% 
  group_by(aisle_id, aisle) %>% 
  count() %>% 
  arrange(desc(n))
head(aisle, n = 1) %>% knitr::kable(align = 'l')
```

There are `r nrow(aisle)` aisles, and most items are ordered from aisle number 83 "fresh vegetables".

<br>

Plot of the number of items ordered in each aisle
```{r}
aisle %>% filter(n > 10000) %>% arrange(desc(n)) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.2) +
  labs(x = "Aisle Name", y = "Number Ordered") +
  scale_y_continuous(
    breaks  = c(20000, 40000,  60000,  80000,  100000, 120000, 140000, 160000)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 55, hjust = 1))
```
 

<br>
Among the aisle  “baking ingredients”, “dog food care”, and “packaged vegetables fruits”, the three most popular and their times of being ordered are shown in table below:

```{r}
popular_item =
  instacart %>% filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarise(order_times = n()) %>% 
  arrange(aisle, desc(order_times)) %>% 
  slice(1:3)

popular_item %>% knitr::kable(align = 'l')

```

<br>

The mean hour of the day at which "Pink Lady Apples" and "Coffee Ice Cream" are ordered on each day of the week are shown below:
```{r}
hour = 
  instacart %>% filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour"
  )

hour %>% knitr::kable(align = 'c', digits = 1)

```

## Problem 2

Load the data from package:
```{r}
data(brfss_smart2010)
brfss =
  brfss_smart2010 %>% janitor::clean_names() %>% 
  filter(
    topic == "Overall Health",
    response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")
    ) %>% 
  mutate(
    response = as.factor(response), 
    response = fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  arrange(response)

```

Find the states that were observed at 7 or more locations:
```{r}
#In 2002:
brfss %>% filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarise(number_observed = n_distinct(locationdesc))  %>% 
  filter(number_observed >= 7) %>% 
  knitr::kable()
```

In 2002, CT, FL, MA, NC, NJ and PA were observed at 7 or more locations;

```{r}
#In 2010:
brfss %>% filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarise(number_observed = n_distinct(locationdesc))  %>% 
  filter(number_observed >= 7) %>% 
  knitr::kable()
```

In 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY and OH were observed at 7 or more locations.



```{r}
#Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state
average = 
  brfss %>% filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarise(avg_value = mean(data_value, na.rm = TRUE)) %>% 
  rename(state = locationabbr) 
#“Spaghetti” plot of this average value over time within a state
average %>%   
  ggplot(aes(x = year, y = avg_value)) +
  geom_line(aes(group = state)) +
  labs(y = "Average Data Value")
```

Two-panel plot showing distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State for the years 2006 and 2010 :
```{r}
#Filter NY state and year
ny_value = 
  brfss %>% filter(year %in% c("2006", "2010"), locationabbr == "NY") %>% 
  select(year, response, data_value)

#Make boxplot
ny_value %>% 
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  facet_grid(~year) +
  labs(y = "Data Value", x = "Response") 
```
Comparing the plots for 2006 and 2010, we can see that the median data value in each response group did not change much except the small elevation in the 'very good' group.

## Problem 3

Read in and clean dataset
```{r message=FALSE}
accel =
  read_csv("./dataset/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    workday = case_when(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
                               day %in% c("Saturday", "Sunday") ~ "weekend"),
    day = as.factor(day), 
    day = fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>% 
  select(week, day_id, workday, day, everything()) 
```

The 'accel' dataset contains `r nrow(accel)` observations and `r ncol(accel)` variables. 
The variable "week", "day", and "workday" indicate the week, the day of the week, and whether it was a weekday or weekend of each observed day; and the variables "activity_n" contain the activity counts for each minute of a 24-hour day.

```{r}
#Compute the sum of activities of each day
accel_sum =
  accel %>% 
  mutate(sum_day = rowSums(.[5:1444])) %>% 
  select(week, day_id, workday, day, sum_day) %>% 
  group_by(week) 

#Line chart of activities of each day across weeks
accel_sum %>%
  ggplot(aes(x = day, y = sum_day, color = week)) +
  geom_point() +
  geom_line(aes(group = week)) +
  labs(x = "Day of Week", y = "Daily Activity Sum")
```
We can see from the resulting graph that, during the first three weeks, the daily total activity was roughly increacing from Monday to Sunday; but in the 4th and 5th week, the total activity increased a bit during weekdays then dopped dramatically on Saturday.

```{r}
#Compute the hourly activity for each day
hour_act = sapply(seq(5,1444,by = 60),function(i) rowSums(accel[,i:(i + 59)]))
sum_hour = cbind(accel, hour_act) %>% select(-starts_with("activity")) %>% 
  pivot_longer('1':'24', names_to = "hour", values_to = "activity" ) %>% 
  mutate(hour = as.numeric(hour)) %>% 
  arrange(day_id, hour)

#Plot the 24-hour activity time courses for each day
sum_hour %>% 
  ggplot(aes(x = hour, y = activity, color = day)) +
  geom_line(aes(group = day_id)) +
  scale_x_continuous(
    breaks = seq(1, 24, by = 1), 
    limits = c(1, 24)) +
  labs(x = "Hour of Day", y = "Hourly Activity")
```

From the resulting graph we can see that the activities fluctuated most at mid-day of Sundays, and at night of Fridays; and there were some fluctuation on Wednesday, Saturday, and Monday.